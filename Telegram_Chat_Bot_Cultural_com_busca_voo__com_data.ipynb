{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eaoliveira/senac-telegram-chatbot/blob/main/Telegram_Chat_Bot_Cultural_com_busca_voo__com_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LuU26lCLmZeV"
      },
      "outputs": [],
      "source": [
        "!pip install groq\n",
        "!pip install python-telegram-bot\n",
        "!pip install scikit-learn\n",
        "!pip install nest_asyncio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "C2WrfeZ_9RMG"
      },
      "outputs": [],
      "source": [
        "# configurando o groq\n",
        "\n",
        "from google.colab import userdata\n",
        "GROQ_API_KEY = userdata.get('GROQ_API_KEY')\n",
        "AVIATION_STACK_API_KEY = userdata.get('AVIATION_STACK_API_KEY')\n",
        "CLIENT_AMADEUS = userdata.get('CLIENT_AMADEUS')\n",
        "SECRET_AMADEO = userdata.get('SECRET_AMADEO')\n",
        "TELEGRAM_BOT = userdata.get('TELEGRAM_BOT')\n",
        "\n",
        "from groq import Groq\n",
        "\n",
        "client = Groq(api_key = GROQ_API_KEY)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvpcfPPrmMkJ",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import asyncio\n",
        "from typing import Any, Dict\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "import nest_asyncio\n",
        "from telegram import Update\n",
        "from telegram.ext import (\n",
        "    Application,\n",
        "    CommandHandler,\n",
        "    MessageHandler,\n",
        "    filters,\n",
        "    ContextTypes\n",
        ")\n",
        "\n",
        "import json\n",
        "import requests\n",
        "from datetime import datetime, timedelta\n",
        "import random\n",
        "\n",
        "# Aplicando nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Configuração do logger\n",
        "logging.basicConfig(\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
        "    level=logging.INFO\n",
        ")\n",
        "\n",
        "\n",
        "# Função para gerar datas aleatórias de partida e chegada\n",
        "def gerar_datas():\n",
        "    partida = datetime.now() + timedelta(days=random.randint(1, 90))\n",
        "    chegada = partida + timedelta(hours=random.randint(5, 15))\n",
        "    return partida.strftime(\"%d/%m/%Y %H:%M\"), chegada.strftime(\"%d/%m/%Y %H:%M\")\n",
        "\n",
        "# Lista de destinos com informações culturais e companhias fictícias\n",
        "destinos = [\n",
        "    {\"nome\": \"Cusco\", \"companhia\": \"Cultura Airlines\", \"descricao\": \"Porta de entrada para Machu Picchu, cheia de história Inca.\", \"tempo_estadia\": \"3 a 5 dias\", \"clima\": \"Moderado a frio\"},\n",
        "    {\"nome\": \"Atenas\", \"companhia\": \"History Flights\", \"descricao\": \"Berço da civilização ocidental, rica em monumentos históricos.\", \"tempo_estadia\": \"4 a 7 dias\", \"clima\": \"Quente no verão, ameno no inverno\"},\n",
        "    {\"nome\": \"Cidade do México\", \"companhia\": \"Maya Wings\", \"descricao\": \"Capital vibrante e cultural do México, cheia de história asteca.\", \"tempo_estadia\": \"5 a 7 dias\", \"clima\": \"Ameno a quente\"},\n",
        "    {\"nome\": \"Roma\", \"companhia\": \"Ancient Travels\", \"descricao\": \"Cidade eterna, cheia de sítios arqueológicos e arte renascentista.\", \"tempo_estadia\": \"5 a 7 dias\", \"clima\": \"Ameno na primavera e outono\"},\n",
        "    {\"nome\": \"Cairo\", \"companhia\": \"Explorer Airways\", \"descricao\": \"Conhecida pelas pirâmides e história do Egito Antigo.\", \"tempo_estadia\": \"3 a 5 dias\", \"clima\": \"Quente e seco\"},\n",
        "    {\"nome\": \"Kyoto\", \"companhia\": \"Heritage Air\", \"descricao\": \"Famosa por seus templos históricos e jardins japoneses.\", \"tempo_estadia\": \"4 a 6 dias\", \"clima\": \"Ameno, com flores de cerejeira na primavera\"},\n",
        "    {\"nome\": \"Paris\", \"companhia\": \"ArtVoyage\", \"descricao\": \"Centro da arte, cultura e história francesa.\", \"tempo_estadia\": \"5 a 7 dias\", \"clima\": \"Frio no inverno, agradável no verão\"},\n",
        "    {\"nome\": \"Istanbul\", \"companhia\": \"Tradition Wings\", \"descricao\": \"Cidade que une o Oriente e o Ocidente, rica em história e cultura.\", \"tempo_estadia\": \"3 a 6 dias\", \"clima\": \"Moderado, frio no inverno\"},\n",
        "    {\"nome\": \"Jerusalém\", \"companhia\": \"Pilgrim Paths\", \"descricao\": \"Cidade sagrada com séculos de história religiosa.\", \"tempo_estadia\": \"4 a 6 dias\", \"clima\": \"Ameno a quente\"},\n",
        "    {\"nome\": \"Fez\", \"companhia\": \"Sahara Sky\", \"descricao\": \"Conhecida por suas medinas e herança cultural marroquina.\", \"tempo_estadia\": \"3 a 5 dias\", \"clima\": \"Quente e seco\"},\n",
        "    {\"nome\": \"Beijing\", \"companhia\": \"Dynasty Air\", \"descricao\": \"Mistura de história antiga e modernidade, com a Grande Muralha próxima.\", \"tempo_estadia\": \"5 a 7 dias\", \"clima\": \"Frio no inverno, quente no verão\"},\n",
        "    {\"nome\": \"Luang Prabang\", \"companhia\": \"Indochina Air\", \"descricao\": \"Cidade Patrimônio da UNESCO, conhecida pelos templos budistas.\", \"tempo_estadia\": \"4 a 6 dias\", \"clima\": \"Ameno com chuvas sazonais\"},\n",
        "    {\"nome\": \"Petra\", \"companhia\": \"Oasis Express\", \"descricao\": \"Cidade histórica esculpida em rochas, conhecida como a cidade rosa.\", \"tempo_estadia\": \"2 a 4 dias\", \"clima\": \"Quente e seco\"},\n",
        "    {\"nome\": \"Cartagena\", \"companhia\": \"Latin Spirits\", \"descricao\": \"Cidade colonial na costa caribenha, cheia de vida e cor.\", \"tempo_estadia\": \"3 a 5 dias\", \"clima\": \"Quente e úmido\"},\n",
        "    {\"nome\": \"Machu Picchu\", \"companhia\": \"Inka Trails\", \"descricao\": \"Antiga cidade Inca nas montanhas dos Andes.\", \"tempo_estadia\": \"2 a 4 dias\", \"clima\": \"Moderado, com chuvas sazonais\"},\n",
        "    {\"nome\": \"Florence\", \"companhia\": \"Renaissance Air\", \"descricao\": \"Berço da Renascença italiana, cheia de museus e arquitetura histórica.\", \"tempo_estadia\": \"3 a 5 dias\", \"clima\": \"Ameno no outono e primavera\"},\n",
        "    {\"nome\": \"Varanasi\", \"companhia\": \"Spiritual Sojourn\", \"descricao\": \"Cidade sagrada na Índia, conhecida pelos rituais no Rio Ganges.\", \"tempo_estadia\": \"3 a 5 dias\", \"clima\": \"Quente e úmido\"},\n",
        "    {\"nome\": \"Marrakech\", \"companhia\": \"Atlas Wings\", \"descricao\": \"Cidade vibrante no Marrocos, com mercados, palácios e jardins.\", \"tempo_estadia\": \"3 a 5 dias\", \"clima\": \"Quente e seco\"},\n",
        "    {\"nome\": \"Lhasa\", \"companhia\": \"Tibet Trails\", \"descricao\": \"Centro espiritual do Tibete, com templos e monastérios antigos.\", \"tempo_estadia\": \"4 a 6 dias\", \"clima\": \"Frio e seco, especialmente no inverno\"},\n",
        "    {\"nome\": \"Seul\", \"companhia\": \"Gyeong Airlines\", \"descricao\": \"Capital da Coreia do Sul, moderna e com rica história cultural.\", \"tempo_estadia\": \"3 a 5 dias\", \"clima\": \"Frio no inverno, quente no verão\"},\n",
        "    {\"nome\": \"Angkor Wat\", \"companhia\": \"Temple Air\", \"descricao\": \"Conjunto de templos antigos no Camboja, patrimônio da humanidade.\", \"tempo_estadia\": \"2 a 4 dias\", \"clima\": \"Quente e úmido\"}\n",
        "]\n",
        "\n",
        "# Cidades de origem\n",
        "origens = [\"São Paulo\", \"Rio de Janeiro\", \"Buenos Aires\", \"Lisboa\", \"Cidade do México\"]\n",
        "\n",
        "# Gerar base de dados com 1000 voos fictícios\n",
        "dados = {\"voos\": []}\n",
        "for i in range(1000):\n",
        "    destino_info = random.choice(destinos)\n",
        "    destino = destino_info[\"nome\"]\n",
        "    companhia = destino_info[\"companhia\"]\n",
        "    origem = random.choice(origens)\n",
        "    numero_voo = f\"{companhia[:2].upper()}{random.randint(100, 999)}\"\n",
        "    data_partida, data_chegada = gerar_datas()\n",
        "    duracao = f\"{random.randint(5, 15)}h {random.randint(0, 59)}m\"\n",
        "    portao_embarque = f\"{random.choice('ABCDEF')}{random.randint(1, 20)}\"\n",
        "    terminal = str(random.randint(1, 5))\n",
        "    disponibilidade = random.choice([\"Disponível\", \"Lotado\", \"Espera\"])\n",
        "    preco = random.randint(500, 7000)  # Preço numérico para facilitar comparação\n",
        "\n",
        "    # Adicionar voo à base de dados\n",
        "    dados[\"voos\"].append({\n",
        "        \"numero_voo\": numero_voo,\n",
        "        \"companhia\": companhia,\n",
        "        \"origem\": origem,\n",
        "        \"destino\": destino,\n",
        "        \"data_partida\": data_partida,\n",
        "        \"data_chegada\": data_chegada,\n",
        "        \"duracao\": duracao,\n",
        "        \"portao_embarque\": portao_embarque,\n",
        "        \"terminal\": terminal,\n",
        "        \"disponibilidade\": disponibilidade,\n",
        "        \"preco\": preco,\n",
        "        \"descricao_destino\": destino_info[\"descricao\"],\n",
        "        \"tempo_estadia\": destino_info[\"tempo_estadia\"],\n",
        "        \"clima\": destino_info[\"clima\"]\n",
        "    })\n",
        "\n",
        "def get_tomorrow_date_formatted():\n",
        "  \"\"\"Gets tomorrow's date in the format used by generate_response.\"\"\"\n",
        "  tomorrow = datetime.now() + timedelta(days=1)\n",
        "  return tomorrow.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "class KnowledgeContextLayer:\n",
        "    def __init__(self):\n",
        "        self.knowledge_base = dados\n",
        "\n",
        "    def get_knowledge(self, key: str) -> Any:\n",
        "        return self.knowledge_base.get(key)\n",
        "\n",
        "class InputLayer:\n",
        "    def __init__(self):\n",
        "        self.intent_examples = {\n",
        "            \"consulta_voo\": [\"qual é o preço do voo\", \"detalhes do voo\", \"horário de partida\", \"quando chega o voo\", \"me fale sobre esse voo\", \"detalhes do voo\"],\n",
        "            \"recomendar_voo\": [\"me recomenda um voo\", \"me sugira um voo\", \"me dê outra opção\", \"tem mais sugestões?\", \"voo com preço baixo\", \"voo com preço alto\"],\n",
        "            \"informacao_destino\": [\"me fale sobre\", \"quero saber mais sobre\", \"tempo de estadia em\", \"clima em\", \"o que tem em\"],\n",
        "            \"saudacao\": [\"olá\", \"oi\", \"bom dia\", \"boa tarde\", \"boa noite\", \"tudo bem?\", \"como vai?\"],\n",
        "            \"conversa\": [\"qual seu nome?\", \"quem é você?\", \"o que você faz?\", \"você é um robô?\"]\n",
        "        }\n",
        "        self.vectorizer = CountVectorizer().fit(sum(self.intent_examples.values(), []))\n",
        "        self.preco_baixo_exemplos = [\"baixo preço\", \"mais barato\", \"com menor preço\", \"voo mais barato\"]\n",
        "        self.preco_alto_exemplos = [\"alto preço\", \"mais caro\", \"com maior preço\", \"voo mais caro\"]\n",
        "\n",
        "    def process_input(self, user_input: str) -> Dict[str, Any]:\n",
        "        intent = self._extract_intent(user_input)\n",
        "        preco_intent = self._extract_preco_intent(user_input)\n",
        "        return {\n",
        "            \"raw_input\": user_input,\n",
        "            \"processed_input\": user_input.strip().lower(),\n",
        "            \"tokens\": user_input.split(),\n",
        "            \"intent\": intent,\n",
        "            \"preco_intent\": preco_intent\n",
        "        }\n",
        "\n",
        "    def _extract_intent(self, user_input: str) -> str:\n",
        "        user_vector = self.vectorizer.transform([user_input])\n",
        "        max_similarity = 0\n",
        "        best_intent = \"consulta_voo\"\n",
        "        for intent, examples in self.intent_examples.items():\n",
        "            example_vectors = self.vectorizer.transform(examples)\n",
        "            similarity = cosine_similarity(user_vector, example_vectors).mean()\n",
        "            if similarity > max_similarity:\n",
        "                max_similarity = similarity\n",
        "                best_intent = intent\n",
        "        return best_intent\n",
        "\n",
        "    def _extract_preco_intent(self, user_input: str) -> str:\n",
        "        user_vector = self.vectorizer.transform([user_input])\n",
        "\n",
        "        # Calcula similaridade para termos de preço baixo\n",
        "        baixo_similarity = cosine_similarity(user_vector, self.vectorizer.transform(self.preco_baixo_exemplos)).mean()\n",
        "\n",
        "        # Calcula similaridade para termos de preço alto\n",
        "        alto_similarity = cosine_similarity(user_vector, self.vectorizer.transform(self.preco_alto_exemplos)).mean()\n",
        "\n",
        "        if baixo_similarity > alto_similarity and baixo_similarity > 0.3:  # Ajuste de limite de similaridade\n",
        "            return \"baixo\"\n",
        "        elif alto_similarity > baixo_similarity and alto_similarity > 0.3:\n",
        "            return \"alto\"\n",
        "        return \"\"\n",
        "\n",
        "class ProcessingLayer:\n",
        "    def __init__(self, knowledge_context_layer):\n",
        "        self.knowledge_context_layer = knowledge_context_layer\n",
        "        self.recommendation_history = []\n",
        "        self.user_context = \"\"\n",
        "        self.conversation_history = []\n",
        "        self.max_history_length = 5\n",
        "\n",
        "    def prepare_context(self):\n",
        "        recent_history = self.conversation_history[-self.max_history_length:]\n",
        "        context = f\"Recent Conversation History: {recent_history}\\nUser context: {self.user_context}\"\n",
        "        return context\n",
        "\n",
        "    def _get_groq_completion(self, query, assistant=None, context=None):\n",
        "        \"\"\"\n",
        "        Sends a query to the Groq API and returns the completion.\n",
        "\n",
        "        Args:\n",
        "            query (str): The user's query.\n",
        "            context (str, optional): The conversation context. Defaults to \"\".\n",
        "            assistant (str, optional): A system-level prompt. Defaults to None.\n",
        "\n",
        "        Returns:\n",
        "            str: The Groq completion response.\n",
        "        \"\"\"\n",
        "        messages = [\n",
        "            {\"role\": \"user\", \"content\": query}\n",
        "        ]\n",
        "        if context:\n",
        "            messages.append({\"role\": \"system\", \"content\": context})\n",
        "        if assistant:\n",
        "            messages.append({\"role\": \"system\", \"content\": assistant})\n",
        "        if assistant:\n",
        "            messages.append({\"role\": \"assistant\", \"content\": assistant})\n",
        "\n",
        "        completion = client.chat.completions.create(\n",
        "            model=\"llama3-70b-8192\", messages=messages, stop=\"```\")\n",
        "\n",
        "        return completion.choices[0].message.content\n",
        "\n",
        "\n",
        "\n",
        "    def generate_response(self, input_data: Dict[str, Any]) -> str:\n",
        "        intent = input_data[\"intent\"]\n",
        "        preco_intent = input_data[\"preco_intent\"]\n",
        "        if intent == \"saudacao\":\n",
        "            return self.handle_conversation(input_data[\"raw_input\"])\n",
        "        elif intent == \"consulta_voo\":\n",
        "            return self.handle_voo_request(input_data[\"raw_input\"])\n",
        "        elif intent == \"recomendar_voo\":\n",
        "            return self.handle_recommendation_request(preco_intent)\n",
        "        elif intent == \"informacao_destino\":\n",
        "            return self.handle_destination_info(input_data[\"raw_input\"])\n",
        "        return self.handle_conversation(input_data[\"raw_input\"])\n",
        "\n",
        "    def get_amadeus_api_token(self):\n",
        "      \"\"\"Retrieves an access token for the Amadeus API.\"\"\"\n",
        "      url = \"https://test.api.amadeus.com/v1/security/oauth2/token\"\n",
        "      headers = {\"Content-Type\": \"application/x-www-form-urlencoded\"}\n",
        "      data = {\n",
        "          \"grant_type\": \"client_credentials\",\n",
        "          \"client_id\": CLIENT_AMADEUS,\n",
        "          \"client_secret\": SECRET_AMADEO\n",
        "      }\n",
        "      response = requests.post(url, headers=headers, data=data)\n",
        "      return response.json()['access_token']\n",
        "\n",
        "    def fetch_flight_offers(self,iata_code, access_token, date):\n",
        "      \"\"\"Fetches flight offers from the Amadeus API.\"\"\"\n",
        "      headers = {\"Authorization\": f\"Bearer {access_token}\"}\n",
        "      params = {\n",
        "          \"originLocationCode\": \"GRU\",\n",
        "          \"destinationLocationCode\": iata_code,\n",
        "          \"departureDate\": date or get_tomorrow_date_formatted(),\n",
        "          \"adults\": 1,\n",
        "          \"currencyCode\": \"BRL\",\n",
        "          \"adults\": 1,\n",
        "          \"max\": 2\n",
        "      }\n",
        "      api_result = requests.get('https://test.api.amadeus.com/v2/shopping/flight-offers', headers=headers, params=params)\n",
        "      return api_result.json()\n",
        "\n",
        "    def extract_iata_code(self, query):\n",
        "      \"\"\"Extracts the IATA code from the query using Groq API.\"\"\"\n",
        "      query = f\"Extraia o iata code do principal aeroporto e a data da viagem no formato yyyy-mm-dd da pergunta como iata_code e date_travel como um JSON object. Se for mencionada uma data sem especificar o ano, e essa data já tiver passado no ano atual, considere que ela pertence ao ano seguinte ao atual {datetime.now()}. Retorne as informações ajustadas dessa forma: {query} \"\n",
        "      response = self._get_groq_completion(query, \"```json\")\n",
        "      return json.loads(response)\n",
        "\n",
        "\n",
        "    def handle_voo_request(self, query):\n",
        "        iata_code_dict = self.extract_iata_code(query)\n",
        "        iata_code =  iata_code_dict['iata_code']\n",
        "        date_travel = iata_code_dict['date_travel']\n",
        "        if not iata_code:\n",
        "            return \"Desculpe, não encontrei aeroporto na localizacao mencionada.\"\n",
        "\n",
        "        access_token =  self.get_amadeus_api_token()\n",
        "        api_response =  self.fetch_flight_offers(iata_code, access_token, date_travel)\n",
        "\n",
        "        if not api_response:\n",
        "            return \"Desculpe, não encontrei informações sobre o voo solicitado.\"\n",
        "\n",
        "        context = self.prepare_context()\n",
        "        query = f\"Responda que está enviando os valores e descreva com um formato adequado para telegram sobre os voos listados com Detalhes do voo,companhia (nome completo), Origem, Destino, Partida (com formato dd/mm/aaaa hh:mm), Chegada (com formato dd/mm/aaaa hh:mm),Duração e Preço (formatado como R$): {api_response} \"\n",
        "        response = self._get_groq_completion(query, None, context)\n",
        "\n",
        "        return response\n",
        "\n",
        "\n",
        "    def handle_recommendation_request(self, preco_intent):\n",
        "        voos = self.knowledge_context_layer.get_knowledge(\"voos\")\n",
        "        if preco_intent == \"baixo\":\n",
        "            voo = min(voos, key=lambda v: v[\"preco\"])\n",
        "        elif preco_intent == \"alto\":\n",
        "            voo = max(voos, key=lambda v: v[\"preco\"])\n",
        "        else:\n",
        "            voo = next((v for v in voos if v not in self.recommendation_history), None)\n",
        "\n",
        "        if voo:\n",
        "            self.recommendation_history.append(voo)\n",
        "            return (f\"Recomendo o voo {voo['numero_voo']} - {voo['companhia']}:\\n\"\n",
        "                    f\"Origem: {voo['origem']} | Destino: {voo['destino']}\\n\"\n",
        "                    f\"Partida: {voo['data_partida']} | Chegada: {voo['data_chegada']}\\n\"\n",
        "                    f\"Duração: {voo['duracao']} | Preço: R$ {voo['preco']:,.2f}\".replace(\",\", \".\"))\n",
        "        else:\n",
        "            return \"Desculpe, não há mais recomendações de voos disponíveis.\"\n",
        "\n",
        "    def handle_destination_info(self, query):\n",
        "        query_lower = query.lower()\n",
        "        try:\n",
        "          query = f\"Extraia o nome, descricao, tempo_estadia (duracao da estadia ideal na cidade), clima e roteiro com foco em atividades culturais com detalhes sobre cada uma pra quantidade de dias sugerida (como um string unica roteiro_viagem, os dias devem ser ter uma quebra de linha entre eles) da pergunta, responda como um JSON object: {query} \"\n",
        "\n",
        "          response = self._get_groq_completion(query, \"```json\")\n",
        "        except Exception as e:\n",
        "          print(f\"Não foi possivel procurar por causa do erro: {e}\")\n",
        "\n",
        "        destino = json.loads(response)\n",
        "\n",
        "        if not destino:\n",
        "            return \"Desculpe, não encontrei informações sobre o destino solicitado.\"\n",
        "\n",
        "        return (f\"Informações sobre {destino['nome']}:\\n\"\n",
        "                f\"Descrição: {destino['descricao']}\\n\"\n",
        "                f\"Tempo de Estadia: {destino['tempo_estadia']}\\n\"\n",
        "                f\"Clima: {destino['clima']}\\n\"\n",
        "                f\"Roteiro: {destino['roteiro_viagem']}\"\n",
        "                )\n",
        "\n",
        "    def handle_conversation(self, query):\n",
        "        query_lower = query.lower()\n",
        "        context = self.prepare_context()\n",
        "        assistant = \"Você é um assistente virtual amigavel e util focado em prover experiencias de turismo e responder perguntas sobre voos chamado SenacTurismoBot, Responda o cliente apenas se for relacionado a viagens e voos e destinos, caso o usuario desvie de assunto, responda que não pode falar sobre esse assunto. Sempre responda em portugues. Utilize o nome do usuário sempre que possivel\"\n",
        "        response = self._get_groq_completion(query_lower, assistant,context)\n",
        "        return response\n",
        "\n",
        "\n",
        "\n",
        "class SCI:\n",
        "    def __init__(self):\n",
        "        self.knowledge_context_layer = KnowledgeContextLayer()\n",
        "        self.input_layer = InputLayer()\n",
        "        self.processing_layer = ProcessingLayer(self.knowledge_context_layer)\n",
        "\n",
        "    def append_to_history(self, user_input, bot_response):\n",
        "        \"\"\"Appends a user input and bot response to the conversation history.\"\"\"\n",
        "        self.processing_layer.conversation_history.append({\"user\": user_input, \"bot\": bot_response})\n",
        "\n",
        "    def append_user_data(self, user_data):\n",
        "      \"\"\"Appends a user name and data to user context.\"\"\"\n",
        "      self.processing_layer.user_context = user_data;\n",
        "\n",
        "    def process_conversation(self, user_input):\n",
        "        input_data = self.input_layer.process_input(user_input)\n",
        "        response = self.processing_layer.generate_response(input_data)\n",
        "        return response\n",
        "\n",
        "\n",
        "sci = SCI()\n",
        "\n",
        "# Função para o comando /start\n",
        "async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    await update.message.reply_text(\n",
        "        \"Olá! Eu sou seu assistente de voos. Pergunte sobre destinos ou preços.\"\n",
        "    )\n",
        "\n",
        "# Função para lidar com mensagens de texto\n",
        "async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    print(update)\n",
        "    sci.append_user_data(f\"Dados do usuário: nome {update.message.chat.first_name} sobrenome {update.message.chat.last_name} idioma ({update.message.from_user.language_code})\")\n",
        "    user_input = update.message.text.strip()\n",
        "\n",
        "    resposta = sci.process_conversation(user_input)\n",
        "\n",
        "    sci.append_to_history(user_input, resposta)\n",
        "\n",
        "    await update.message.reply_text(resposta)\n",
        "\n",
        "# Configuração do bot\n",
        "async def main():\n",
        "    TOKEN = TELEGRAM_BOT\n",
        "    application = Application.builder().token(TOKEN).build()\n",
        "\n",
        "    application.add_handler(CommandHandler(\"start\", start))\n",
        "    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))\n",
        "\n",
        "    print(\"Bot iniciado...\")\n",
        "    await application.run_polling()\n",
        "\n",
        "# Executando o bot\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8BZ9ioOd1Z9m"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}